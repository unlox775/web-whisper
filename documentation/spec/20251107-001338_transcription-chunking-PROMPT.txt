start working on round two of this application which is breaking up the audio into logical chunks that will fit better for transcription to start i don't want to do any actual audio preparation or stitching things together or anything like that i'm just gonna have you read from our current chunking thing here i want to have only debugging mode a new button that shows up when you're viewing a recording which would be c um yeah i think just like a graph icon or something like that and ultimately what i want to see i want to start exercising the things in the architecture where we're talking about a threshold of when things are quiet. So ultimately I think I want to show a rectangle on the screen, this graph, and it's going to show basically it's a volume histogram. That's all I care about at the moment is just volume histogram of the entire length of the audio, you know highs and lows, and then ultimately I want to start the logic of parsing it to actually start listening listening to the audio. The main thing you're gonna have to look at is go through and actually parse the audio just for the sake of pulling out audio. Any fancy audio flushing and noise filtering you can do blurring or however it works. That's up to you. My naive mind doesn't know anything about when there are quiet sections. theoretically I want to show maybe a dashed a line across the grid as to what we are computing as the silence base you know in other words if there a fan in the background if there just general noise if there's roar there whatever it is um first thing i also want to do is have you automatically scale so that the peak is near the top because if we have a really quiet microphone which is what it appears i don't want this back this rectangle that you're showing the graph in and I want it to auto scale it up so that the peaks are near the top, probably not touching the top, but near the top. And hopefully that dashed line is somewhere below there as to where the noise line is. And that's what we're assuming is quiet. And then ultimately I want you to show in the logic that we're looking for, trying to aim for certain people, probably pause for longer times between things that they say. I wanna show some type of a colored vertical bar, top to bottom, that's the width of those pauses. So we're trying to do a pause detection, fuzzy logic here. And by tuning this, I'll give you different recordings in different environments, and we'll try seeing what this graph looks like in different places. The goal we're looking for here is to identify threshold and try to ultimately tune our thing the goal we're looking for is probably 10 to 30 seconds every 10 to 30 seconds or so um a logical break that that is a theoretically a place we're thinking would be an okay place to create an audio file based off of everything up to that point, cobble it together into a new audio file, and that would be a chunk sending it off to for thing up to that point, cobble it together into a new audio file, and that would be a chunk sending it off to for transcription, theoretically, would be a useful transcription to not get cut off mid sentence or mid word or something else like that. And we're just trying to find and maybe this maybe can go up to a minute maybe 10 seconds to a minute is our goal um if they didn't say if the entire transcription is less than a minute or so or less than 30 seconds i think we just keep it um let's say if it's less than 10 seconds let's keep it but um otherwise we're looking at uh how about this if if it's less than 10 seconds no logic of just we'll keep it but that changes our algorithm to what essentially we're going to change our threshold of how long of a pause is a transcription break and we're going to adjust that threshold down until the size of gaps of audio between transcription things is it's kind of a goal-seeking algorithm I think that the algorithm of that the breaks in the different transcription things is about the target we want, you know, 10 to 60 seconds. And if there's obvious blocks that are, and I think down to five seconds is probably good. You know, it's maybe five to 60 seconds, but we just don't want to have, we know when it's wrong, we know when it's the average length is like less than five seconds or the average length is probably less than 10 seconds. We just want an okay average, but if there's an obvious quiet pause in the middle there and the recording is only 15 seconds long, that's okay for the one to be eight seconds, the one to be three seconds or something. Theoretically, when we do pause in the middle there and the recording is only 15 seconds long. That's okay for the one to be 8 seconds, the one to be 3 seconds or something. Theoretically, when we do have the slices, we're going to identify a point right in the center of the actual quiet spot. I'd like that to be like a vertical yellow line as to the actual cut that we're going to make. So maybe like a color vertical red or something of that bar, which is the entire width of the part we think is quiet. And then a little yellow vertical slice line as to the actual line where we're going to cut it. But yeah, I'm thinking you're going to make some kind of a audio analysis to find the transcription snips. The one thing you'll, that needs to be relatively fast because you'll actually be running this analysis while the recording is going. So you can automatically be finding these chunks and doing that. So these are relatively fast and durable to analyze a bunch of files. This is where it would be helpful for you to tell me what audio files you want me to give you. so you can make unit tests to do these analyses, to read it in and to test stuff. And yeah, mainly I just want you to take a good guess as to where the pauses should be, what the low noise level threshold should be. That'll be the other thing we do for goal seeking. We'll raise the noise level until there's at least enough breaks that it looks like the right volume, number of snips or a number of pauses in there. And a lot of the pauses are gonna be gaps between two words. And that's not a good point to break. We wanna wait for the larger of those ones to try and see if we can discover ends of paragraphs, that type of thing. And then that will be what we theoretically can snip and send off to transcription. But this visualizer graph will help us see that. I'll try it with multiple different audio files and we'll see if it's doing a good job at detecting these good places to break.
