Okay. I think it's time to come up with... A list of final polish things to be done. You know there is a there is no I'm avoiding that we're going to need to port this to an iOS application soon. The main missing gap, of course, is that I want to be able to hit record and have it keep recording in the background while I switch to other applications. Because often that's how I dictate my inputs is to browse to other applications. So, I don't know if there's any way to get the progressive web app on. iOS anyways, to stay persistent so it keeps recording even when you're not on the application. But there are definitely some other things that need to be adjusted. I want you to create this as like a documentation slash roadmap maybe. Identify maybe a... List of tasks. I wanted to keep it relatively terse at this point of what it is, what the task is, what the main goals are, and two or three bullet items as to the most effective acceptance criteria to know that they're done. One feature. is we haven't implemented the data deletion process. Essentially, when you start getting closer to the limit that is set, it's not auto-deleting things. The general way I want to do the deletion is to delete oldest files first, but only deleting the audio chunk files for... chunks that are part of SNPs that have finished transcribing. And then we need to have a thing where if you do retry transcription, it won't allow a retry of those transcriptions because the chunks are gone now. So they're like locked or something. but I want this deletion to be automatic as you're recording new chunks, probably on some type of, I don't know, debounced event firing or something, like every new event fires a thing, which then causes every two minutes for it to do a deletion pass where it finds and deletes and purges old stuff to keep it under the limit. So deletion. That needs to go down eventually. I think I want to have a... Getting started slow. People need to know how to get on here, how to go and get a Grok key. You know, explaining them that the Grok API for this type of a thing is so insanely cheap. even though it will show a few cents usage even after they use it all the time. I'm sure some people will prove me wrong, but... Even after they used it as heavily as I do, which is pretty darn heavily. Um... Cough. Cough. Cough. Cough. even after I've done thousands and thousands of recordings like I have I've still never been charged It is a pay-as-you-go model, at least until they discontinue that. So it's so cheap that you... In practice, we'll never actually end up paying for the actual dictation transcription part. But it's something to walk them through the general steps of how to do that, where to go, set up the account, explain the cost worries or lack of worries, but with the disclaimer. But ultimately, when you just have a first time using this app, you're going to wonder how to get the transcription to work. We need to have a little bit better... Planned out value of the app. Assuming you haven't enabled transcription yet. I think I'd probably prefer it to be like the app has essentially two modes. Either you haven't enabled transcription or you have. And in order to enable transcription, you have to give it a valid rock key. We double-check it. And there's a state in the future where the grok key no longer seems to work, in which case they can either hit Retry to switch back to transcription-enabled mode, But when you're in transcription enabled mode, I think all the recordings should just, you know, not show transcription failed because obviously it can't. start those ones. Maybe it's like recording complete or something? I don't know. Because you can still play it. Use it as a general audio recorder. It's not very useful, but... The other thing that would be good to know, I don't think we have a download button for downloading the entire audio. That would be definitely useful to do. yeah I'm sure there's a bunch of visual improvements and such that would be good to have on here, but I don't think that I don't need to worry about those yet. I think I want to do some focus groups with some people, record what they're... response reactions are to the app, what they like, what they don't like, usability questions and such. but don't really care that much that it looks pretty you did a pretty good job enough of making it look pretty to my eyes so And that is the plan. Another feature, I guess, it's a body of work anyways. is to do some more cross-browser testing. Because I've verified that on iOS, the version that I'm using, it works. But either a different phone or a different iOS version or even a different computer like it works okay on my Chrome and brave on my desktop machine. I went to test it the other day on some other computer or a PC or something, and it did not work. I don't know what the errors were, but it's not very cross-browser compatible yet at the moment. But, anyhow, those are the main roadmap items I can think of. I want you to capture all those ones. The major roadmap item, I suppose, is iOS. I think I would just probably build iOS build. There's just a subfolder in here. I don't know. I don't know. I'll probably build it as a subfolder here. I'd want it to be as minimal as possible where I can give it my Apple credentials. But this is an open source application, so anybody should be able to plug in their Apple credentials and make a duplicate app if they want to. I just want to get a... What do they call it? Anyway. I almost have it. On Apple Developer, there's some... Initial launch pad or something. A test. I don't know the name of it. But I've used I've done iOS apps before and there's a way to like get the local signing key and they can install it locally on your one machine Because you have that local identity set up or whatever Let's you actually have it on your machine And then eventually put it to the app store. I don't think I ever intend to charge money for it. Paying my $100 a year Apple fee is good enough for me. I think for support, I would just say if you have any issues, go submit it on the GitHub repository. And if anyone wants to help fix it... then I encourage them to use AI. I've got all the history of all the prompts and how I built this thing recorded on AI in the history. So... I encourage anybody to go on there and just talk to AI and see if you can fix the bugs. I think I probably will consider merging it in. I don't know. It's not my goal to... Yeah, it's not really my goal to keep, to whittle off a little bit of my time to maintain this thing. So I would probably need someone else as the main maintainer of this. So, anyway. I'm just sharing it because the joy of using AI and having to create tools for you should also have some kind of a... where you can dump those tools to the rest of the world. I've built so many of these that I can't afford the effort of trying to port. to dilute my time to the community maintenance support of these I build these tools so that I can use them not really for the sake of you know creating a passion project that I want to be on forever more utility and usefulness than anything else. Anyway, I'd want to explain all that stuff. So you can probably capture that in the roadmap of my intent and plan to long-term maintenance and such. Yeah. I'll probably make sure the main repository readme is up to date with some of these roadmap plans as well. But, yeah. Thank you. Thank you.
Weird. Some of the road map items to capture. There's still the outstanding bug. On iOS anyways, it may be an iOS framework or somewhere, a glitch or something, who knows. But every once in a while I'll just... I won't connect to the microphone. Still have no idea how to debug that further. So this is maybe not a roadmap item, but maybe known issues and bugs still to be solved. There are a set of road map things to be good to have that are maybe going to be iOS only features like First, it's just the creation of the web app that acts exactly the same as the mobile, the make, the app, whatever the app, I don't know. Features that only work if the thing is built as an iOS or Android app. Android's not really on my... Roadmap. Maybe you can make a roadmap if anyone else wants to help contribute. Contributions roadmap that I am not interested in pursuing, but that someone else as a contributor could totally come and support this thing. Just use AI, generate the damn thing. It's super easy nowadays. Yeah. iOS are done as an actual first class application on the phone features. I think the main transcription screen, instead of copying it, you have to click on it and click on it and then hit copy. I think just have a... First, have it auto-copy as soon as the recording is stopped and the transcription is finished. Auto-copy and broadcast. Hey, transcription copied or something. I'll figure out how to do that to put it under the clipboard. But then also add a to every transcription. Probably the ones, only the ones with complete transcriptions. I suppose it's fine to have a copy icon on a half completed transcription. Anyway, on the main tile, when you haven't clicked on it yet, there should just be an actual copy icon. You click it and it'll copy it to the clipboard. when you click on the thing and you go into something and you hit copy for that I don't know for sure that Apple iOS lets you copy in that way you might have to do it the way I'm doing it where you click on it and click on it again or long press it or something like that but some easier way to copy it to your clipboard it's the main use case of this thing But that's the main thing that I'm thinking. I'm sure we'll find other ones. Oh, another contribution roadmap item. The first one was Android. But then the other one is localization. I'm working in so you can have different languages besides English. That's another thing I'm not going to be working on. It's okay to define them all there on the roadmap.
No, I really was meaning what I've said. I want a roadmap.md file for roadmap items only. Then I want a knownissues.md for issues I know need to be fixed. I may not get around to them, but there are known issues. And you can give more detail on that. You can even look at past debugging specs. You can read the details on that. capture any more detail on the known issues in case someone else decides to grab and tackle them. But then I want an entirely separate contributor feature, maybe a contributor roadmap, as a separate markdown file. I want this one roadmap. to mention the other two, like with file links, but I don't want you to actually include all that content in the main roadmap. Update all that, please.
Alright, small update to the known issue of it not working. It's not a very good workaround, and it's also not super consistent, but I found when it's in the middle of a recording session that is ultimately going to fail, because it's sitting there stuck on the starting screen. This is updating the known issues markdown file, but we just made, just add more details as a possible workaround whenever you see this. while it's in that if I on iOS swipe up to go to the like app toggle the tab between apps I hear on my phone a little b-deep tone And if I go back to the app it makes a higher beep tone It doesn't actually work at that point. It'll still end up dying and ending in that one. But if I then delete the recordings... then switch to another app and switch back. Then I have to start another recording. It's been working. I think I've done that two or three times now. I'm not sure if that gives us any clues to solving it, but at least it's a little more practical. You don't get stuck forever. Maybe instead of just swiping up... I didn't actually switch to the app on that first attempt. It worked. Second time I did, it didn't seem to work. So I had to switch back. It could have been a timing thing. Could have been that I didn't wait for it to actually stop. Anyway, I actually switched to the other app. completely on that first toggle and then went back and then waited for the recording to stop and then deleted those recordings. I don't know what it could be but a little more information is all to add to that known issue. Okay, the other thing I wanted you to do, I want to talk a little bit about how to use AIs. I think if you were to... measure how open and vulnerable you are being with another human being. You could in some ways measure it as are you communicating your true feelings? Your internal dialogue, is it filtered when you say it out loud? If something is just really confusing you and driving you crazy, at what point do you just give up and stop telling other people what you really think and then switch to triage mode to let's just, you know, not compromise, not the goal that I was looking for, but essentially start weeding out of the conversation. I think that's a normal, natural thing that most people have when they're talking to another human. And I think that carries over when people go to AI. So when you're talking to an AI and you're asking what you want, most people are still stuck in tier one, which is I'm going to type it out just like I would have typed a search query in Google or something. I have to describe what I want. Maybe I've learned that I need to give it more, maybe double, triple what I would have given Google before. so that I can do a better job of getting it right, I need to spend more time on describing the context before, you know, I need to do whatever. So they might give it, you know, 50 words at the tops, maybe. You know, 20 words is... probably more average. And that's those people I'm not talking about because they haven't figured out how AI works. I'm talking about the people that are using dictation like this app inspires people to do. So I think this is all going to probably be stored in like a how to use AI, how this app can help, AI, you know, pointers and tips and... But ultimately, the thing I want to get to is that I think people need to learn to become completely vulnerable when they're talking to AI. I think if you're in a room with other people listening to you dictate to AI, you're going to be way significantly worse at giving it the information you need to. If you're confused, you're not going to do a good job of communicating what's confusing you. You're going to flail. You're going to ultimately be frustrated with AI and maybe tell yourself, well, AI is just dumb anyways. But in reality, you just need to be more vulnerable. You need to just let it out. similar you know exercises people have done in the past to get vulnerable is in creative writing which is called flow you just flow and let whatever come out when you're a therapist you eventually realize there's a safe space there and so you can just let him have it and just say all the mean things that are in your head and you know be open be out those are the things that inspire this kind of a mode talking to AI and it lets you see really what's inside of your own head that's why it's good in therapy that's why it's good for creative writing to finally get over your mental blocks on stuff But ultimately, and I think in nearly all of this you can keep and just clean up the wording to make it more approachable to other people. Because this is basically a talk I've wanted to give to other people. But that, I think, is important. But that also means there's some uglies that come out, too. Like, in general, I am a polite person. I generally don't swear, even in most common casual conversation. I think swearing is... In that context, something, the spice of life, the spice of conversation, sarcasm, some of the other finer, masterful points in conversation and dialogue, can be spiced up by a cuss word here or there. But, the point of it often is, in intense moments, is to convey extreme emotion. I think if you're not... Some people aren't that passionate maybe in general, but if you're not being passionate in your AI usage, you are maybe not going to be that effective at your AI usage. So, I think I challenge you to become more passionate. And part of that starts with, give it what you're thinking. Even if you're cussing in your head about this stupid AI and how you told it this. but it didn't understand that, and it did this instead, the things that this will do, it will reveal your own ignorances about the things that you're working on. The things that you think you thought you knew, and you told AI to do, and even though you may have said all the words correctly, did the wrong thing because your picture of the world of whatever app you're trying to build, whatever feature you're wanting, whatever technology you're involved with is wrong. I'll give you a great example that I ran into with this app. I bashed back and forth, back and forth. You can see all my chat transcripts on this repository. And I bashed back and forth yelling at and cursing at and cussing out the AI agent because it couldn't fix the chunk playback thing. The audio was supposed to come out in 4 second chunks, in which I guess it was basically following that thing. I could see the stream chunk 0, 1, 2, 3, 4, and it ultimately was not... working when you went to go play back chunk one it was like a garbled mix of like chunk one and chunk three and two had some of the stuff from the first four seconds it was just garbled it was just terrible and i was so mad at it because i it was simple in my mind as you have chunk one it's four seconds chunk two is four seconds wanted you to have a button to play back chunk one and I couldn't for the life of me figure out why it was wrong when I looked at my histogram of all the different audio and the different chunks in order. I had it generate a volume map of each chunk because I assumed they were all sequential and you could just play it back. I was so mad and I got so cursed up, cursed up, you know, passionate about this. I could have just given up. And I think I probably would have just given up if I didn't have this passion, if I didn't learn how to turn on this, turn off this filter and to be vulnerable. But because I pushed through it, I eventually realized I didn't understand fundamentally the audio technology involved in this API I was using. The API I was using, some web audio API. Please go back and find the actual names for the technologies here. This is the point where I sound smart because I figured out what was wrong. But ultimately, it comes out an MPEG... audio chunks which are not sequential. It is a container format. So things are going to come out semi-random and it gives information about how to stitch it all back together. But the audio files are not sequential. I don't know if it's for compression or for whatever purposes. It ends up coming out in four-second-ish chunks that don't have sequential audio there. Different snips of different audio that can be stitched together to make the final MPEG audio product. but without having the full stream, you can't do almost anything that I wanted to do. I wanted to let it play back the first four seconds of audio. That didn't work. And so by... sticking with it by yelling at it a lot, especially if I did a better job. It was not a great moment that I'm proud of. It took me a long time to finally realize where the problem was. what bit of the technology I was not getting. It did lead me down some really good debugging paths so I could understand the internals of what was going on better. But in the end, it didn't make any sense why it was doing that. The thing I finally realized that I was wrong is that audio MPEG coming out in random sequence was not going to work and that I needed to switch to raw PCM audio. Which is really big and so now I need to figure out how to compress the audio But then I can actually get the four second audio chunks that I want There are some small download quality things. There's little blips every 4 seconds because it's the end of one MP3 and the start of another MP3. But now it uses MP3, I think, as the encoding for it. It works. So, in short, all this is to explain why if you go back and you read those, you're going to see a lot of swear words. I think for the sake of tender minds and people that want to not see all those, I'm going to have AI now go and bleep those out. But I encourage you to go back and look for the commit that... last touched each one of those spec files and have it look at the change. You can see my raw swear words if you want. It is vulnerable, it is me, and I'm not afraid to admit that I am very passionate about this stuff. It is what it is. So, end of basically what the content is I want of that article. And that was essentially almost a whole speech in order that I wanted to cover that thing. I think there's a lot of cleanup you can do to make me not circle the topic quite as much. But generally, keep most all of that segment there. But now I want you to go do what I said in here. I want you to go into the spec files and look for times when I actually swore. I'm looking for darn it and freaking and junk and butt maybe I don't think I see that word very often But look for all those and see if you can just switch the word out. I don't want to really do the F asterisk, asterisk, asterisk, because that's just as bad when you're reading it. I think just switch it to a more benign way to say that same thing. So find all those instances, do a bunch of individual edits to edit each one of those so it is more sanitized. Yeah, that's what I want you to go do. If that's enough for good instructions, go for it.
