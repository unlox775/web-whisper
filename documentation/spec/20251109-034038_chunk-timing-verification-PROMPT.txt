<user_query>
All right, I think it's time for a semi-major overhaul of reorganizing how audiophiles are gathered, are treated over time, and ultimately how they are re-audited and updated. We have this concept of a chunk volume model and that's the point when we are the first time that we have loaded the audio waveform into memory and we know how long it is. I think we need to isolate all the things that manage all the chunks in a given session into more of an organized provider. Ultimately this is a library you have internally, but I think some of the qualities I want the new one to be is that initially all of the values of the chunks that are existing start out with the initial values you have right now is chart time and end time, which are essentially unverified. Maybe we have a status of unverified and for backwards compatibility it's assumed if it doesn't have a verified status of verified then it is unverified. But I think what we want to do is have a status equals verified, which means that for things to be verified a session level pass needs to be completed. It could happen if chunks volumes are loaded independently, that's fine, but once the last chunk volume has been calculated, which should happen regularly during the course of a session, being viewed everything but the session sequence zero because it has no length. But I think you need to have it recompute all of the actual start and end time dates relative based off of the start time of the zeroth session. So this will be like a session specific method which would go through, have all of the verified audio milliseconds in place, and once it's actually analyzed each one of those and they're verified, just start with the start at time of the initial session, the sequence zero, and then just automatically add each of those verified milliseconds on there so that the start and end times on each one of those are accurate. And we're literally gonna be destructive, we're gonna override what those initial ones are, we're just assuming they are untrusted because they're essentially polluted by the natural event stream differences and whatever will cause waits or delays, will cause jitter that we just don't need. Ultimately if we know the start thing, and we know all the verified length of each one of the audio files, we can exactly predict all of them and we know at that point what we can mark them all out as. So it doesn't mean we're gonna be modifying the actual chunks thing, we're gonna set the status when we're done on each chunk to verified, maybe like, you know, chunk timing verified is true or something like that, or chunk timing status is verified or something like that. And ultimately by doing that we're gonna fix a lot of these weird glitches we have right now of past sessions that I have recorded are just showing all over the place, like sometimes they overlap, sometimes it's showing one thing coexisting during the same time as another, and I think it's just because we're using those start time milliseconds and end time milliseconds to graph things out when we're doing the real-time histogram. So I think that ultimately needs to happen at some point. I think this is something a good excuse to make more official the session management, the things that it owns, things that the chunks themselves own, which shouldn't be very much. Session manager basically should own the object of the chunks and the chunk volumes. They could have their own sub models, have their own methods that exist on a model level, but the other thing I want you to do is do a lot better job at commenting all this stuff, because I think being intentional on what's happening on which things and how we're doing it, the sequence of recording it, the sequence of where the events were catching. When I was reading through that code, there were like zero comments in there. I want this spelled out much easier, so someone that isn't as familiar with the audio flow here. I'm thinking even multi-line and paragraph-sized comments on different places to explain what's going on, how things are working, make it look stupid simple, and yeah, see if you can get that to work. This probably doesn't need a whole new version of the chunk volume or the chunks thing, just adding a new column that will automatically regenerate those values in there. And essentially when a session is loaded, sometime something needs to be triggering, hey, all the chunks have their verified timings true or statuses true or verified, so therefore let's have it go recompute all of the actual start things and mark everything as verified. The session itself will also be marked as verified timings complete or something, and that would cause a later check to not even worry about it because it's already been completed. Anyway, that's a cleaning that I think we can do and that'll clean up a lot of the weird data issues and stuff we're seeing.
</user_query>
<user_query>
all right I think we have some visual bugs so I looked at the new verified statuses and stuff like that and that seems to be okay one thing I think we maybe need to unify better into our model on the session is I'm not sure how it's currently building the histogram but theoretically we can generate the whole histogram without any you can build the histogram without any accessing of the audio file itself because we have these chunk volumes recorded what I am seeing though especially now that our chunk volumes things are littered just arrays of integers we know that are just all 50 milliseconds apart I'm seeing the graph zigs up and down up and down as it goes from left to right on the x axis and then at some point it zigs backwards that same line draws backwards to the left to about the five second mark or so and then zigs up and down up and down more to the right and then it continues on after that and then later on closer toward the end it zigs from you know the last 20 seconds or so to the end so it's like they did the y then the y-axis so the x-axis on a bunch of these points it just got shifted that would only make sense if you are picking you know making essentially a bunch of two-dimensional points my guess is that this is screwed up because the way you're getting it is some convoluted way that you're directly accessing these models rather than just you know doing our chunk session store thing and asking for the entire list of integers a list of float values for the entire thing that automatically it's all the different chunk things together because you shouldn't need y-axis or x-axis values they're all just incremental integers as it goes along another thing that appears to be just wrong in the user interface when you're opening up the recorded session panel on our recorded session page this one shows that it was captured from 11 32 p.m. to 8 52 a.m. I'm wondering if you're updating it as the that that captured whatever you're putting from there pulling totally the wrong values this is a 23 second clip and it's at eight hours anyway I don't know that session if you're recalculating and doing the verified things you should have a very handy start and end time for the session that is verified by the lengths the start time and all the lengths of all the audio clips and all the sequence I don't know if you're doing that based on the last updated time that needs to be updated the other thing is the histogram is the x-scale is a lot zoomed more zoomed in than I thought we had planned the entire width of the view I thought was supposed to be 30 seconds and I think it's somewhere close to 10 seconds let's have it be let's just go somewhere in between let's have it be 20 seconds for the entire view let's do this go to 30 30 seconds just scale on the x-axis 30 seconds of audio will show in the view before I have to scroll yeah just go and see if you can clean up and figure out what other reasons this was going sideways

Also, make a note on your    level of comments is still not high enough. Every function should have a comment before  and I think on average, you should have an    every 3 to 5 instructions  the comment walking through the steps of what it is doing   is
</user_query>
