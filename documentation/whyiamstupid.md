## `whyiamstupid.md` ‚Äî What exactly happens when you press Play

This document is a ‚Äútrace log in English‚Äù: what the app does, in order, when you press the different **Play** buttons.

The goal is to make the ‚Äúmystery‚Äù concrete:

- **Full-session play** sounds correct end-to-end.
- **Chunk play / Snip play** (in the üêû debug panel) can sound like it repeats the beginning, loops, or blends audio from different places.

That can only happen if those buttons are **not using the same decoding/timebase assumptions**, even if they‚Äôre reading from the same IndexedDB rows.

---

## What‚Äôs the data model (in IndexedDB)

### Sessions table: `sessions`
- Stored via `manifestService.createSession()` / `updateSession()`.
- Key: `SessionRecord.id`
- Important fields for playback:
  - `startedAt` (epoch ms)
  - `durationMs` (verified-ish, can be updated later)
  - `mimeType`
  - `chunkCount`

### Chunks table: `chunks`
- Stored via `manifestService.appendChunk(chunkRecord, blob)`
- Indexed by `by-session` (sessionId).
- Each row is a `StoredChunk`:
  - `id` = `${sessionId}-chunk-${seq}`
  - `seq` (0 = header/init-ish chunk, >0 = actual audio chunks)
  - `startMs`, `endMs` (captured/verified timing; **can be absolute epoch ms** in this codebase)
  - `blob` (the MediaRecorder output blob for that `dataavailable` event)

### Volume profiles table: `chunkVolumes`
- Stored via `manifestService.storeChunkVolumeProfile(profile)`
- Each row includes:
  - `seq`, `chunkStartMs`, `chunkEndMs`
  - `durationMs` (decoded duration of the analysis blob)
  - `frameDurationMs` (default 50ms)
  - `frames[]` (normalized per-frame ‚Äúenergy‚Äù)

Important: volume profiles are created by decoding a blob with `AudioContext.decodeAudioData()` in `computeChunkVolumeProfile()`. For MP4 fragments, browsers may report durations in ways that don‚Äôt match your intuitive ‚Äú4 second timeslice‚Äù expectation.

---

## A. ‚ÄúNormal Play‚Äù (the big ‚ñ∂ button on the session detail)

### UI entrypoint (React)
File: `src/App.tsx`

When you press the big playback button (the one that plays the whole recording), the app calls:

- `handlePlaybackToggle()`

### Step-by-step call chain

1) **`handlePlaybackToggle()`**
   - Ensures there is an audio source prepared.
   - Grabs `audioRef.current` (a hidden `<audio>` element in the DOM).

2) **If needed: `preparePlaybackSource()`**
   - Chooses a mime type: `selectedRecording.mimeType ?? 'audio/mp4'`.
   - Calls:
     - `manifestService.buildSessionBlob(sessionId, mimeType)`

3) **`manifestService.buildSessionBlob(sessionId, mimeType)`**
   - Opens IndexedDB (`getDB()`).
   - Reads all chunks for the session:
     - `db.transaction('chunks').store.index('by-session').getAll(sessionId)`
   - Sorts by `seq`.
   - Returns a single `Blob` built as:
     - `new Blob(ordered.map(c => c.blob), { type: mimeType })`

4) **Back in `preparePlaybackSource()`**
   - Creates an object URL:
     - `URL.createObjectURL(blob)`
   - Assigns it to the DOM `<audio>` element:
     - `audio.src = url`
     - `audio.currentTime = 0`

5) **Back in `handlePlaybackToggle()`**
   - If paused: `audio.play()`
   - Else: `audio.pause()`

### What happens while it ‚Äúmoves through chunks‚Äù

This is the key point:

- The ‚Äúnormal play‚Äù path does **not** ‚Äúplay chunk 1 then load chunk 2 then‚Ä¶‚Äù.
- It hands the browser a **single Blob URL** and then the browser‚Äôs MP4 demuxer/decoder plays it as one stream.
- The app does not manually stitch or schedule chunk boundaries.

### How does it know playback is progressing / ended
React attaches listeners to `audioRef.current`:

- `timeupdate` ‚Üí updates `audioState.position`
- `durationchange` ‚Üí updates `audioState.duration`
- `play/pause/ended` ‚Üí updates `audioState.playing`

So ‚Äúfinished‚Äù is just the browser firing `ended`.

### Why this can sound correct even if chunk-by-chunk sounds wrong

Because the browser is decoding a single stream. Any oddities in individual chunk blobs (cumulative timestamps, edit lists, etc.) can be resolved differently when:

- the MP4 is concatenated, and
- the demuxer can see a continuous timeline.

This path is ‚Äúclosest to what the browser expects‚Äù.

---

## B. üêû Debug panel ‚Üí ‚ÄúChunks‚Äù ‚Üí per-row Play

File: `src/App.tsx`

The chunk list rows call:

- `handleChunkPlayToggle(chunk)`

### The old (problematic) mental model
‚ÄúEach chunk row plays only that chunk‚Äôs audio from 0..4 seconds.‚Äù

### What actually happens in browsers that emit cumulative MP4 chunks
Some MediaRecorder implementations can output ‚Äúchunks‚Äù where each `dataavailable` blob is effectively:

- chunk 1 blob: audio 0..t1
- chunk 2 blob: audio 0..t2
- chunk 3 blob: audio 0..t3

Even though we *intend* timeslices, the blob content can be cumulative in time.

If you then do:

- createObjectURL(chunk2.blob)
- `audio.currentTime = 0`
- play for 4 seconds

you will hear **the beginning of the recording again**.

That‚Äôs exactly your symptom: ‚Äúchunk 2 starts with the beginning of chunk 1‚Äù.

### What the code does today (current branch state)

To make this path robust (and simpler), we changed debug chunk playback to **not play the MP4 chunk blob directly**.

Instead it:

1) Computes the chunk‚Äôs time window in ‚Äúsession offset ms‚Äù:
   - base start = `seq0.startMs` (header) or `session.startedAt`
   - `startOffsetMs = chunk.startMs - baseStartMs`
   - `endOffsetMs = chunk.endMs - baseStartMs`

2) Uses the same range-extraction API as snips/doctor:
   - `recordingSlicesApi.getRangeAudio(session, startOffsetMs, endOffsetMs)`

3) That returns a **WAV** blob for exactly that time span.

4) Creates `URL.createObjectURL(wavBlob)` and plays it with `new Audio(url)` from t=0.

### Why chunk 2 used to differ from chunk 1 / chunk 3

If the browser makes cumulative blobs, then:

- chunk 1 (0..t1) played at t=0 sounds ‚Äúright‚Äù
- chunk 2 (0..t2) played at t=0 repeats the beginning
- chunk 3 repeats even more

So the *difference* is not ‚Äúour code treats chunk2 differently‚Äù ‚Äî it‚Äôs that the blob content is different: it‚Äôs cumulative.

---

## C. üêû Debug panel ‚Üí ‚ÄúSnips‚Äù ‚Üí per-row Play

File: `src/App.tsx`

Snips are derived from `SessionAnalysisProvider` (volume profiles ‚Üí analysis frames ‚Üí boundaries ‚Üí segments).

When you press snip Play:

- `handleSnipPlayToggle(segment)`

### Step-by-step

1) `handleSnipPlayToggle(segment)` resolves a URL via `ensureSnipPlaybackUrl(segment)`
2) `ensureSnipPlaybackUrl` calls `ensureSnipSlice(segment)`
3) `ensureSnipSlice` calls:
   - `recordingSlicesApi.getRangeAudio(session, segment.startMs, segment.endMs)`
4) That returns a **WAV** blob.
5) The UI plays that WAV blob from t=0 using `new Audio(url)`.

### Why snips could ‚Äúloop the first second‚Äù (the classic symptom)

There are two distinct failure modes we‚Äôve seen in this repo:

#### 1) **Range extraction is wrong**
If range extraction maps ‚Äúsession time‚Äù to ‚Äúchunk time‚Äù incorrectly (especially with cumulative blobs), you can repeatedly extract from near t=0.

That produces audio that is ‚Äúthere once was a‚Ä¶‚Äù over and over, because the extracted buffer is effectively the same first second.

This is why `recordingSlicesApi` had to learn about cumulative chunks and, when detected, slice by absolute session offsets inside a single cumulative buffer (instead of subtracting chunk start offsets and stitching).

#### 2) **Caching key collisions**
If the app uses a cache key that collides across snips, multiple snip rows can reuse the same URL/blob.

Example: `Math.round(startMs)` based keys can collide when boundaries are close or fractional.

That‚Äôs why snip caching keys were moved to stable identifiers (e.g. `snip-${segment.index}`).

---

## D. Why ‚Äúfull play works‚Äù but ‚Äúchunk/snip play fails‚Äù (the short diagnosis)

Full play:
- Uses `manifestService.buildSessionBlob()` ‚Üí one MP4 blob ‚Üí browser decodes as a continuous stream.

Chunk/snip play:
- Works in **session offset space**, and must map offsets to the right decoded audio samples.
- If the underlying MediaRecorder blobs are cumulative, naive ‚Äúplay blob from t=0‚Äù or naive offset mapping will replay the beginning.

So the app needs to either:

- treat chunk blobs as *containers that may contain other times* (cumulative), or
- avoid MP4 fragment playback for debug buttons and always play extracted WAV ranges.

This repo is moving toward the second approach for debug buttons because it‚Äôs deterministic and debuggable.

---

## E. The exact ‚Äúmystery‚Äù you described

> Full play is perfect. Chunk 1 plays fine. Chunk 2 starts with a snippet from the beginning of chunk 1, then continues with its own stuff.

That is exactly what you get when:

- chunk2‚Äôs underlying blob includes audio starting at 0 (cumulative timeline),
- and the UI plays chunk2 starting at t=0,
- or slices chunk2 using an offset mapping that assumes the blob starts at the chunk‚Äôs start time.

The correct fixes are:

- detect ‚Äúcumulative chunk‚Äù behavior and slice by absolute session offsets; and/or
- switch debug playback to generated WAV slices so playback is always ‚Äúplay exactly these samples‚Äù.

---

## F. Where to look in code (quick pointers)

- **Full play:**
  - `src/App.tsx` ‚Üí `handlePlaybackToggle()` ‚Üí `preparePlaybackSource()`
  - `src/modules/storage/manifest.ts` ‚Üí `buildSessionBlob()`

- **Chunk debug play:**
  - `src/App.tsx` ‚Üí `handleChunkPlayToggle()`
  - `src/modules/playback/recording-slices.ts` ‚Üí `getRangeAudio()` / range decoding helpers

- **Snip debug play:**
  - `src/App.tsx` ‚Üí `handleSnipPlayToggle()` ‚Üí `recordingSlicesApi.getRangeAudio()`
  - `src/modules/analysis/session-analysis-provider.ts` ‚Üí volume profile concatenation

